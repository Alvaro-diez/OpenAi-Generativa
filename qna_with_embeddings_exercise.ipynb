{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service - Q&A with semantic answering exerise\n",
    "\n",
    "In this tutorial, you'll build a simple Q&A system, that can give semantic answers to questions. Three sample documents from the Azure documentation are provided. Fill out the missing pieces in the source source to get everything working (indicated by `#FIXME`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai==0.28.1\n",
      "  Using cached openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==0.28.1) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==0.28.1) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==0.28.1) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.9.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28.1) (0.4.6)\n",
      "Using cached openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.59.7\n",
      "    Uninstalling openai-1.59.7:\n",
      "      Successfully uninstalled openai-1.59.7\n",
      "Successfully installed openai-0.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "  WARNING: The script openai.exe is installed in 'C:\\Users\\Alumno_AI\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "# from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "api_type = \"azure\"\n",
    "api_version = \"2022-12-01\"\n",
    "api_base = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=api_base,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-09-01-preview\"\n",
    ")\n",
    "client2 = openai.AzureOpenAI(\n",
    "    azure_endpoint='https://alvar-m5xnib7a-swedencentral.cognitiveservices.azure.com/',\n",
    "    api_key=\"24ymwZq2Hrj8GheFk2mzgXfHJSEPmPcmonZnAnnMXHvB3LAKj13BJQQJ99BAACfhMk5XJ3w3AAAAACOGm1Bp\",\n",
    "    api_version=\"2022-12-01\"\n",
    ")\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "EMBEDDING_ENCODING = 'cl100k_base'\n",
    "EMBEDDING_CHUNK_SIZE = 8000\n",
    "COMPLETION_MODEL = 'davinci-002'\n",
    "\n",
    "# initialize tiktoken for encoding text\n",
    "encoding = tiktoken.get_encoding(EMBEDDING_ENCODING)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's read the documents in `/data/qna/*.txt`, which are our sample documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Content:  # What is conversational language understanding? Conversational language unders... \n",
      "---> Tokens: 1341\n",
      "\n",
      "Content:  # What is Azure OpenAI? The Azure OpenAI service provides REST API access to Op... \n",
      "---> Tokens: 1891\n",
      "\n",
      "Content:  # What is Azure Cognitive Services Translator? Translator Service is a cloud-ba... \n",
      "---> Tokens: 739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all files in the samples directory\n",
    "samples_dir = os.path.join(os.getcwd(), \"./data/qna/\")\n",
    "sample_files = os.listdir(samples_dir)\n",
    "\n",
    "# read each file and remove and newlines (better for embeddings later)\n",
    "documents = []\n",
    "for file in sample_files:\n",
    "    with open(os.path.join(samples_dir, file), \"r\") as f:\n",
    "        content = f.read()\n",
    "        content = content.replace(\"\\n\", \" \")\n",
    "        content = content.replace(\"  \", \" \")\n",
    "        documents.append(content)\n",
    "\n",
    "# print some stats about the documents\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "for doc in documents:\n",
    "    num_tokens = len(encoding.encode(doc))\n",
    "    print(f\"Content: {doc[:80]}... \\n---> Tokens: {num_tokens}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all documents loaded, we can embed them using our embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for all docs\n",
    "embeddings = []\n",
    "for doc in documents:\n",
    "    response = client.embeddings.create(model=EMBEDDING_MODEL, input=doc)\n",
    "    embeddings.append(response.data[0].embedding)\n",
    "\n",
    "\n",
    "# print some stats about the embeddings\n",
    "for e in embeddings:\n",
    "    print(len(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our embeddings, we can try to ask some questions and see if it retrieves the correct document. You can try the following questions:\n",
    "\n",
    "* what is azure openai service?\n",
    "* can translator be fine tuned?\n",
    "* what is the difference between luis and clu?\n",
    "* what is form recognizer? (should yield no result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity to overview_clu.txt is 0.7744814220828408\n",
      "Similarity to overview_openai.txt is 0.8682318308941729\n",
      "Similarity to overview_translator.txt is 0.7929442705877128\n",
      "Matching document is overview_openai.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# create embedding for question\n",
    "question = \"what is azure openai service?\"\n",
    "qe = client.embeddings.create(model=EMBEDDING_MODEL, input=question) #FIXME\n",
    "qe_embedding = qe.data[0].embedding\n",
    "\n",
    "# calculate cosine similarity between question and each document\n",
    "similarities = cosine_similarity([qe_embedding], embeddings)[0] #FIXME\n",
    "\n",
    "# Get the matching document, in this case we just use argmax of similarities\n",
    "max_i = np.argmax(similarities) #FIXME\n",
    "\n",
    "# print some stats about the similarities\n",
    "for i, s in enumerate(similarities):\n",
    "    print(f\"Similarity to {sample_files[i]} is {s}\")\n",
    "print(f\"Matching document is {sample_files[max_i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question was: what is azure openai service?\n",
      "Retrieved answer was:  Azure OpenAI Service is a [PLAINTEXT.](https://en\n"
     ]
    }
   ],
   "source": [
    "# Generate a prompt that we use for completion, in this case we put the matched document and the question in the prompt\n",
    "prompt = f\"Document: {documents[max_i]}\\n\\nQuestion: {question}\\n\\nAnswer:\" #FIXME\n",
    "\n",
    "# get response from completion model\n",
    "response = client2.completions.create(\n",
    "    model=COMPLETION_MODEL,\n",
    "    prompt=prompt\n",
    ") #FIXME\n",
    "answer = response.choices[0].text #FIXME\n",
    "\n",
    "# print the question and answer\n",
    "print(f\"Question was: {question}\\nRetrieved answer was: {answer}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that worked. Now we should have a simple understanding how Q&A can work using Azure OpenAI Service embeddings and completions. Next step would be:\n",
    "\n",
    "* Chunking of longer documents (you might run into token limits for embeddings and the answering prompt)\n",
    "* Usage of a vector database (pinecone, redis, etc.) to scale the search part to a larger amount of documents\n",
    "* Evaluation of the top k results, instead of just the best matching document\n",
    "* ...and a few more!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
